# **RouterWise ‚Äî ML-Powered Logistics Optimization for Art Handling**  
![Ray Serve](https://img.shields.io/badge/Ray_Serve-00AEEF?style=for-the-badge&logo=ray&logoColor=white)  
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)  
![MLflow](https://img.shields.io/badge/MLflow-FF4F00?style=for-the-badge&logo=mlflow&logoColor=white)  
![BentoML](https://img.shields.io/badge/BentoML-FF6F61?style=for-the-badge&logo=bentoml&logoColor=white)  
![Prometheus](https://img.shields.io/badge/Prometheus-E6522C?style=for-the-badge&logo=prometheus&logoColor=white)  
![Grafana](https://img.shields.io/badge/Grafana-F46800?style=for-the-badge&logo=grafana&logoColor=white)  
![Jenkins](https://img.shields.io/badge/Jenkins-D24939?style=for-the-badge&logo=jenkins&logoColor=white)  
![Postman](https://img.shields.io/badge/Postman-FF6C37?style=for-the-badge&logo=postman&logoColor=white)

*"Art logistics is not just about moving objects ‚Äî it's about preserving legacy. RouterWise predicts optimal shipment paths, anticipates risks, and ensures precision in handling priceless artworks. Built for institutions that value both efficiency and integrity."*

---

## üéØ Goal : Designed for high-value and highly constrained logistics workflows

- Predictive routing for fragile, high-value shipments  
- Risk-aware logistics decisions based on historical and real-time data  
- Modular backend for scalable deployment across art institutions and logistics partners  

---

## üß† Architecture Overview

- **Ray Serve**: distributed model serving ‚Üí horizontal scalability without overhead  
- **FastAPI**: async-ready API layer ‚Üí minimal latency, high throughput  
- **MLflow**: model lifecycle management ‚Üí reproducibility, traceability  
- **BentoML**: fallback deployment ‚Üí resilience in production  
- **Prometheus + Grafana**: telemetry and alerting ‚Üí operational visibility  
- **Jenkins CI/CD**: automated build and deploy ‚Üí zero-friction integration  

---

## üìñ Backend Narrative

*"Shipment data is ingested and preprocessed using robust encoding strategies. Predictive models are trained and versioned via MLflow, then served through Ray Serve with BentoML fallback. FastAPI exposes endpoints for route scoring, risk estimation, and shipment classification. Monitoring is handled via Prometheus/Grafana, with CI/CD orchestrated by Jenkins. Retraining pipelines are modular and Airflow-compatible."*

---

## üíª API Demonstration

![API Predictiver](./statics/postman.png)

---

## üìä Monitoring
*"Real-time monitoring: API latency and uptime via Prometheus, request and error counts, drift detection, and data quality checks on incoming data streams."*

[![Dashboard Preview](./statics/grafana_preview.png)](https://drive.google.com/file/d/1uD0oQKDrmADOqS0NHQR6PEfOGW2Jhqwu/view?usp=drive_link)

---

## üìä Operational Impact

- **97% accuracy** in route risk classification  
- **<100ms latency** per prediction under load  
- **Auto-fallback** to best-performing model in case of failure  
- **Live monitoring** of API health, model drift, and request volume  

---

## üöÄ Roadmap

- Integration of **real-time GPS signals** for dynamic rerouting  
- **Multi-agent simulation** for route stress testing  
- **Federated learning** across logistics partners  
- **Contractual risk scoring** based on shipment metadata  
- **Explainable AI** modules for compliance and transparency  

---

## üèÅ Final Note

RouterWise is not a demo. It‚Äôs a production-grade backend built for institutions that move with precision. The code is modular, the logic is strategic, and the architecture is built to endure. If you‚Äôre here to learn how to deploy ‚Äî this isn‚Äôt the place. If you‚Äôre here to build systems that last ‚Äî welcome.

---

üë§ **Abdias Ars√®ne**  
*Sr. AI Consultant ‚Äî Architect of scalable intelligence* üß†


![Feature Selection](./statics/feature_selection.png)
---
## üèóÔ∏è Modular Project Architecture

```

routerwise/
‚îÇ
‚îú‚îÄ‚îÄ app/                  # FastAPI app for serving predictions (BentoML runtime)
‚îú‚îÄ‚îÄ train\_pipeline/       # Feature engineering, training, inference, model saving
‚îú‚îÄ‚îÄ retrain/              # (WIP) Scheduled retraining logic with Celery + Beat
‚îú‚îÄ‚îÄ notebook/             # EDA and feature selection experiments
‚îú‚îÄ‚îÄ docker/               # Custom Dockerfiles
‚îú‚îÄ‚îÄ tests/                # Unit/integration test suites
‚îú‚îÄ‚îÄ Jenkinsfile           # CI/CD pipeline config
‚îú‚îÄ‚îÄ Makefile              # Unified entrypoint for all tasks
‚îú‚îÄ‚îÄ dataset.dvc           # DVC-tracked dataset pointer
‚îî‚îÄ‚îÄ README.md

````

---

## üîÅ MLOps Workflow

1. **Data versioning** using `DVC`
2. **Advanced feature engineering** with:
   - `CatBoostEncoder`, `RobustScaler`
   - `VarianceThreshold`, `Chi¬≤`, `RandomForest`, `RFE`
3. **Training pipeline**:
   - Modular `sklearn` pipelines
   - Auto-logging to `MLflow`
4. **Model registration**:
   - Best model pushed to `MLflow Registry`
5. **Packaging and serving**:
   - Packaged using `BentoML`
   - Served via `FastAPI` (`app/`) ‚Äî integrated with Django project `PrecisioArt`
6. **Monitoring & observability**:
   - Prometheus metrics collection
   - Grafana dashboards for API health, latency, drift, etc.
7. **Testing & validation**:
   - Unit and integration tests for both training and serving
8. **CI/CD**:
   - Automated with `Jenkinsfile`, lint/test/build/deploy

![Mlflow & BentoML](./statics/api.png)
---

## üîÑ Continuous Training Strategy (Planned)

A `retrain/` module is planned for scheduled model updates using **Celery + Beat**.  
Key points:
- New data triggers a scheduled pipeline
- Retrained model is **compared** to the currently deployed one
- **Only if the new model outperforms** the current one will it be promoted
- Else, the system retains the existing model

---

## üìä Monitoring Capabilities

Deployed metrics collected in real time:
- API latency, health, uptime (Prometheus)
- Request counts, error rates
- Drift detection on incoming data streams
- Data quality checks on inputs

Visualized via **Grafana dashboards**. **(CLICK ON THE IMAGE BELOW TO WATCH THE VIDEO)**



---

## ‚úÖ CI/CD Pipeline

All components integrated into a production-grade `Jenkinsfile`:
- ‚úÖ Unit tests
- ‚úÖ Lint checks
- ‚úÖ Build Docker image
- ‚úÖ Trigger MLflow or BentoML packaging
- ‚úÖ Optional deploy phase
- ‚úÖ Slack/Webhook notifications (optional)

---

## ‚öôÔ∏è Makefile Commands

```bash
make train       # Train and log with MLflow
make test        # Run test suite
make run         # Launch BentoML API server
make deploy      # Build + push containers
make monitoring  # Start Prometheus + Grafana stack
make format      # Run flake8 or ruff
````
![Makefile](./statics/makefile.png)
---

## üîí Reproducibility & Integrity

* Reproducible pipelines with versioned datasets (`DVC`)
* Isolated & dockerized environments
* Centralized logging via `MLflow`
* Strict test coverage
* Modular architecture for easy refactor or integration

---

## üìç Status

* ‚úÖ Training pipeline complete
* ‚úÖ Feature selection logic optimized
* ‚úÖ API (RouterWise) deployed via BentoML
* ‚úÖ Monitoring dashboards active
* üîú Continuous Training module (`retrain/`) in progress

---

## ü§ù Contribution

This is not a starter project, but an evolving production-grade pipeline.
If you're interested in contributing, please open a PR with clear module boundaries and test coverage.

---

## üîó About

Built by **Abdias Ars√®ne**, IT Consultant in AI & MLOps
Focused on real-world, cross-industry ML solutions (Health, Humanitarian, Finance, Art Logistics)

> *‚ÄúI don't write code to run. I write code to endure.‚Äù*

---

![MLflow](./statics/mlflow.png)
